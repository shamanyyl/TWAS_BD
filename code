BD GWAS summary statistics used:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8192451/

GWAS summary statistics are publicly available on the PGC website (https://www.med.unc.edu/pgc/results-and-downloads)



The detailed steps of the analysis are:
(1) Estimate the heritability of the phenotype (gene expression) and stop if it is not significant;
(2) Cross-validation of the set models;
(3) Final estimation of the weights calculated for each set model and storage of the results.


The process is briefly described below:

1. Processing the expression file
Produce a BED file from the gene expression matrix and gene location file;
The Count matrix is first TPM normalized with the following R script:

library(rtracklayer)
library(tidyverse)
## Download the gtf file ftp://ftp.ensembl.org/pub/release-75/gtf/homo_sapiens/Homo_sapiens.GRCh37.75.gtf.gz
gtf = rtracklayer::import("D:/Learning Files/LIBD/TPM_matrix/Homo_sapiens.GRCh37.75.gtf.gz")
class(gtf)
gtf = as.data.frame(gtf);dim(gtf)
table(gtf$type)

#1. Pick the longest transcript of a gene
library(tidyverse)
tra = gtf[gtf$type=="transcript",
          c("start", "end", "gene_name")]
length(unique(tra$gene_name))
glt = mutate(tra, length = end - start) %>%
  arrange(desc(length)) %>%
  filter(!duplicated(gene_name)) %>%
  select(c(3,4))
head(glt)
write.csv(glt,'gene_longest_transcript_length.csv')

#count values to TPM
exp<- read.csv("mRNA/SYMBOL_count_matrix.csv",header = T,check.names=F)#read gene file
input<- read.table("gene_longest_transcript_length.txt",header = T)#Extract a total of two columns of genes and length from the txt file
library(dplyr)
merge <- merge(exp,input,by="gene_id")#merge based on gene that column
merge <- na.omit(merge)#remove rows with wrong values
write.csv(merge,file = "mRNA/merge.csv")#write the merge results to a new file, run it straight down maybe

#2. Calculate TPM
## Before calculating, we need to filter (10>counts in 80+% samples), that is, the sum of sample counts should be greater than 453*0.8*10=3624
mycounts<-read.table("mRNA/final_uniq_LIBD_mRNA_TPM.txt",check.names = F,header = T,row.names = 1)
#rownames(mycounts)<-mycounts$gene_name
#mycounts<-mycounts[,-1]
head(mycounts)#last column length is gene_length
dim(mycounts)
#TPM calculation
kb <- mycounts$length / 1000
kb
countdata <- mycounts[,1:453]
rpk <- countdata / kb
rpk
tpm <- t(t(rpk)/colSums(rpk) * 1000000)
dim(tpm)
head(tpm)
write.csv(as.data.frame(tpm), "LIBD2_mRNA_expression_TPM.csv",row.names =T)
### Successfully got the TPM converted count matrix (corrected for sequencing depth and gene length)

And use Perl script to get the position information of the genes in the TPM matrix from the input file "geneloc.txt" of running MatrixEQTL, and paste it into a BED file with the following format:
#CHR start end ID LC01A1H LC01B2S LC02B1H LC02B4B LC02B6B LC03B2B
1 11869 14412 DDX11L1 13.3544344 2.906765619 5.506709558 4.099876917 6.447439428 12.41534336

Finally, using the genotype file after imputation, run FUSION for WGTLIST calculation.

2. Use FUSION's FUSION.compute_weights.R script to create the WGTLIST file.

cd /gpfs/home/dangxl/data/TWAS/WEIGHTS/20220429_KY_family

# Make the WEIGHTS file in this folder
mkdir tmp
mkdir KY
mkdir HSQ
ln -s . / output

The WEIGHTS_KY.sh script looks like this:

#! /bin/bash
#module load plink2
GCTA="gcta_nr_robust"
PLINK="plink --allow-no-sex"
GEMMA="~/miniconda3/envs/ldsc/bin/gemma"
FUSION="/gpfs/home/dangxl/biosoft/fusion_twas-master"

PRE="new_KY"
NR=1

### Input files needed.
# "$PRE.normalized_expression.bed.gz.HEADER" is generated by `zcat [bed.gz] | head -n1 | tr '\t' '\n'`
# "$PRE.covariates.txt.covar" is a PLINK format covariates file
# "$PRE.normalized_expression.bed.gz" is the gzipped bed format expression matrix
# ---

mkdir . /tmp/$PRE.$NR
rm -f HSQ/$PRE.$NR.hsq HSQ/TSPEC.$PRE.$NR.hsq

COVAR="$PRE.covariates.txt.covar"
zcat $PRE.normalized_expression.bed.gz | tail -n+2 | awk -v i=$NR 'NR > (i-1)*100 && NR <= i*100000' | while read PARAM; do
# PARAM contains the expression values for this gene
GNAME=`echo $PARAM | awk '{ print $4 }'`
CHR=`echo $PARAM | awk '{ print $1 }'`
P0=`echo $PARAM | awk '{ p=$2 - 500e3; if(p<0) p=0; print p; }'`
P1=`echo $PARAM | awk '{ print $3 + 500e3 }'`
OUT="tmp/$PRE.$NR/$PRE.$GNAME"

# Conver the expression matrix to a PLINK format phenotype
echo $GNAME $CHR $P0 $P1
echo $PARAM | tr ' ' '\n' | paste $PRE.normalized_expression.bed.gz.HEADER $PRE.normalized_expression.bed.gz.HEADER - | tail -n+5 > $OUT.pheno

# Extract the locus around this gene
rm -f $OUT.bed
$PLINK --silent --bfile family_minimac3_imputation_QC2 --chr $CHR --from-bp $P0 --to-bp $P1 --make-bed --out $OUT --pheno $OUT.pheno --keep $OUT. pheno ---maf 0.0001
if [ ! -f $OUT.bed ]; then
continue
bed ]; then continue

# Run FUSION
FINAL_OUT="/gpfs/home/dangxl/data/TWAS/WEIGHTS/20220429_KY_family/output/$PRE/$PRE.$GNAME"
/gpfs/software/R-3.6.0/bin/Rscript $FUSION/FUSION.compute_weights.R \
--bfile $OUT --tmp $OUT.tmp --out $FINAL_OUT --verbose 0 --save_hsq --PATH_gemma ~/miniconda3/envs/ldsc/bin/gemma --models blup,lasso,top1, enet --hsq_p 1.0
cat $FINAL_OUT.hsq | awk -vw="$PRE $w" '{ print w,$0 }' >> HSQ/$PRE.$NR.hsq
rm -f $FINAL_OUT.hsq
rm $OUT.*
rm -fr tmp/$FINAL_OUT.hsq
rm -fr tmp/$PRE.$NR
touch HSQ/$PRE.$NR.done

Run it to get the "KY.*Gene.wgt.RDat" WEIGHTS file for each gene, totaling 8118.


3. Modify the GWAS summary statistics file format:

The ldsc environment needs to be activated:

conda activate ldsc
~/biosoft/ldsc/munge_sumstats.py --sumstats final_depression_genome-wide.txt --N 500199 --out PGC_meta_md

Run it to get the file
PGC_meta_mdd.sumstats.gz

The file format is as follows:
SNP A1 A2 Z N
rs2326918 A G 1.777 500199.000
rs66941928 T C 0.062 500199.000
rs7190157 A C 0.526 500199.000
rs12364336 A G 1.163 500199.000
rs6977693 T C 1.460 500199.000
rs12562373 A G 1.493 500199.000
rs4766166 A G 0.323 500199.000
rs35621824 A C 1.091 500199.000

4. Run FUSION for TWAS analysis:
#! /bin/sh
for chr in {1..22}
do
/gpfs/software/R-3.6.0/bin/Rscript /gpfs/home/dangxl/biosoft/fusion_twas-master/FUSION.assoc_test.
---sumstats PGC3_core_TWAS.sumstats --weights /gpfs/home/dangxl/data/TWAS/KY_family/WEIGHTS_use/KY_weights.pos \
--weights_dir /gpfs/home/dangxl/data/TWAS/WEIGHTS/20220429_KY_family/ \
--ref_ld_chr /gpfs/home/dangxl/data/TWAS/LDREF/1000G.EUR. \
--chr ${chr} \
--out . /SCZ_PGC3.${chr}.dat
done

Get TWAS results *.dat file on 22 chromosomes:
PANEL FILE ID CHR P0 P1 HSQ BEST.GWAS.ID BEST.GWAS.Z EQTL.ID EQTL.R2 EQTL.Z EQTL.GWAS.Z NSNP NWGT MODEL MODELCV.R2 MODELCV.PV TWAS.Z TWAS.
NA /gpfs/home/dangxl/data/TWAS/WEIGHTS/20220429_KY_family//KY/KY.ABHD13.wgt.RDat ABHD13 13 108870727 108886603 0.11843 rs1105451 4.25 rs1926526 1.19e-01 4.31 -1.9100 403 1 top1 0.12 0.00016 -1.9100 0.05613

5. Visualize the results:
mv SCZ_PGC3.1.dat final_KY_TWAS_SCZ_PGC3.txt
cat *.dat >> final_KY_TWAS_SCZ_PGC3.txt

Remove the header for each chromosome result in the file "final_KY_TWAS_SCZ_PGC3.txt";

The qqman package was used for visualization in R4.1.1:

setwd("D:/help/2022.04.20_Enclosed_Family_line_eQTL/TWAS/")
gwas <- read.table("PGC_UKB_depression_genome-wide.txt",header = T)
gwas$OR <- exp(gwas$LogOR)
head(gwas)
write.table(gwas, "add_OR_PGC_UKB_depression_genome-wide.txt")

rm(list = ls())
library(qqman)
bleeding3 <- read.table("final_KY_TWAS_SCZ_PGC3.txt ", head=TRUE)
bleeding3 <- bleeding3[-which(is.na(bleeding3[,9])),]
0.05/5326
#9.387908e-06
manhattan(bleeding3,chr="CHR",bp="P0",p="TWAS.P",snp="ID",col = c("#5481E4", "#E02939"),
          main = "KY_family_SCZ_PGC3_TWAS",
          annotatePval = 9.387908e-06,
          genomewideline = -log10(9.387908e-06))




